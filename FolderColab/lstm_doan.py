# -*- coding: utf-8 -*-
"""LSTM_DoAn

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t6oiuBs4nAsvN8zf3UI8Rfn8Nr2xD63q
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
import matplotlib.pyplot as plt
import os
import joblib

def load_and_preprocess_data(file_path, sequence_length=50):
    df = pd.read_csv(file_path)
    X = df.iloc[:, :-1].values
    y = df.iloc[:, -1].values

    label_encoder = LabelEncoder()
    y_encoded = label_encoder.fit_transform(y)
    y_one_hot = to_categorical(y_encoded)

    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    num_samples = len(X_scaled) // sequence_length
    X_sequences = []
    y_sequences = []

    for i in range(num_samples):
        start_idx = i * sequence_length
        end_idx = start_idx + sequence_length
        X_sequences.append(X_scaled[start_idx:end_idx])
        y_sequences.append(y_one_hot[end_idx - 1])

    X_sequences = np.array(X_sequences)
    y_sequences = np.array(y_sequences)

    scaler_path = '/content/drive/MyDrive/LSTM_DoAn/scaler.pkl'
    label_encoder_path = '/content/drive/MyDrive/LSTM_DoAn/label_encoder.pkl'

    try:
        joblib.dump(scaler, scaler_path)
        joblib.dump(label_encoder, label_encoder_path)
        print(f"Đã lưu StandardScaler tại: {scaler_path}")
        print(f"Đã lưu LabelEncoder tại: {label_encoder_path}")
    except Exception as e:
        print(f"Lỗi khi lưu scaler hoặc label_encoder: {e}")

    return X_sequences, y_sequences, label_encoder

def build_lstm_model(input_shape, num_classes):
    model = Sequential([
    LSTM(512, return_sequences=True, input_shape = input_shape),
    Dropout(0.2),
    LSTM(256, return_sequences=True),
    Dropout(0.2),
    LSTM(128, return_sequences=True),
    Dropout(0.2),
    LSTM(64),
    Dropout(0.2),
    Dense(num_classes, activation='softmax')
    ])
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

def train_model(model, X_train, y_train, X_val, y_val, epochs, batch_size):
    # Callback để dừng sớm
    early_stopping = EarlyStopping(monitor='val_accuracy', patience=50, restore_best_weights=True, mode='max')

    # Callback để lưu mô hình tốt nhất
    model_checkpoint = ModelCheckpoint('/content/drive/MyDrive/LSTM_DoAn/best_yoga_pose_model.h5', monitor='val_accuracy', save_best_only=True, mode='max')

    # Callback để giảm Learning Rate động
    reduce_lr = ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=30,
        min_lr=0.00001,
        verbose=1
    )

    history = model.fit(
        X_train, y_train,
        epochs=epochs,
        batch_size=batch_size,
        validation_data=(X_val, y_val),
        callbacks=[early_stopping, model_checkpoint, reduce_lr] # Thêm reduce_lr vào callbacks
    )
    return history

def evaluate_and_predict(model, X_test, y_test, label_encoder):
    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)
    print(f"\nĐộ chính xác trên tập kiểm tra: {accuracy:.4f}")
    print(f"Loss trên tập kiểm tra: {loss:.4f}")

    predictions = model.predict(X_test[:10]) # Dự đoán 10 mẫu để khớp với in ấn
    predicted_classes = np.argmax(predictions, axis=1)
    true_classes = np.argmax(y_test[:10], axis=1) # Lấy 10 nhãn thực tế

    print("\nDự đoán cho 10 mẫu đầu tiên:")
    for i in range(10): # Vòng lặp từ 5 thành 10
        predicted_label = label_encoder.inverse_transform([predicted_classes[i]])[0]
        true_label = label_encoder.inverse_transform([true_classes[i]])[0]
        print(f"Mẫu {i+1}: Dự đoán = {predicted_label}, Thực tế = {true_label}")

def plot_training_history(history, save_dir="/content/drive/MyDrive/LSTM_DoAn/"):
    # Tạo thư mục nếu nó chưa tồn tại
    os.makedirs(save_dir, exist_ok=True)

    # Biểu đồ Accuracy
    plt.figure(figsize=(12, 6))
    plt.plot(history.history['accuracy'], label='Training Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.title('Training and Validation Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.grid(True)
    plt.savefig(os.path.join(save_dir, 'accuracy_plot.png'))
    plt.show()

    # Biểu đồ Loss
    plt.figure(figsize=(12, 6))
    plt.plot(history.history['loss'], label='Training Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title('Training and Validation Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)
    plt.savefig(os.path.join(save_dir, 'loss_plot.png'))
    plt.show()
if __name__ == "__main__":
    file_path = '/content/drive/MyDrive/LSTM_DoAn/Data_Training.csv'


    sequence_length = 100
    batch_size_for_training = 32

    print("Bước 1: Tải và tiền xử lý dữ liệu...")
    X, y, label_encoder = load_and_preprocess_data(file_path, sequence_length)

    print("\nBước 2: Chia dữ liệu thành tập huấn luyện và kiểm tra...")
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)


    print("\nBước 3: Xây dựng mô hình LSTM...")
    input_shape = (X.shape[1], X.shape[2])
    num_classes = y.shape[1]
    model = build_lstm_model(input_shape, num_classes)
    model.summary()

    print("\nBước 4: Huấn luyện mô hình...")
    history = train_model(model, X_train, y_train, X_test, y_test, epochs=1000, batch_size=batch_size_for_training)

    print("\nBước 5: Đánh giá và dự đoán...")
    evaluate_and_predict(model, X_test, y_test, label_encoder)

    print("\nBước 6: Vẽ biểu đồ quá trình huấn luyện và lưu lại...")
    plot_training_history(history)

    print("\nQuá trình hoàn tất.")